\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{xfrac}

\usepackage{type1cm}

\newtheorem{theorem}{Théorème}

\title{Informatique Scientifique par la Pratique\\Rapport du cours}
\author{Raphaël BERTHIER, Alban PIERRE et Luca WEHRSTEDT}

\begin{document}
\maketitle

\section{Swarm autohealing}

Au tout début nous étions intéressés par le problème de swarm autohealing, présenté au premier cours par Remi Geraud. Il s'agissait de modéliser le comportement d'un ensemble d'agents dans un espace qui, en conditions normales, produisent du profit mais qui peuvent être compromis et commencer à coûter. En ce cas les agents voisins peuvent organiser un vote pour décider de tuer l'agent compromis ou de le réparer, avec des coûts liées a chaque option.

Le défi principal de ce problème était que c’était à nous de concevoir et proposer une formalisation appropriée. Nous avons donc commencé avec le cas le plus simple, où les agent ont information complète sur l’état de tout le système, sur le profit et le coût dans les différents régions de l'espace, sur le mouvement futur des autres agents. Nous avons étudié le cas d'un espace fini et d'un espace continu. Dans les deux, en fait, la décision optimale des agents voisins pendant le vote était facile à déterminer : il faillait simplement estimer le gain futur de l'agent et le comparer avec le coût du sauvetage. Le calcul consiste en la résolution d'un système linéaire dans le cas discret et d'une [qu'est-ce que il était ? un intégral ou une équation aux dérivées partielles ?] dans le cas continu.

Même la généralisation à l'information incomplète ne nous a apporte aucun résultat d’intérêt : le mieux que nous avons trouvé était de laisser estimer à chaque agent le gain en se basant sur les information qu'il possédait. La seule astuce dans le problème était de ne pas faire choisir aux agent l'option la plus profitable mais de faire leur choisir aléatoirement entre les options possibles en utilisant le gain pour déterminer la probabilité de chaque option : cela évite un ``effet seuil''.

Nous avons donc décidé d'abandonner cette direction et de nous dédier à une piste différente.

\section{Modèle de Krause pour la dynamique d'opinion}

Dans le modèle de Krause on étudie des agents (normalement un nombre fini, mais ils existent des généralisations à un nombre infini, dénombrable ou continu) qui sont caractérisés par leur opinion, qui est une valeur dans un certain espace (normalement un intervalle borné de $\mathbb{R}$). Le système évolue à étapes. A chaque étape les agents se déplacent (tous au même temps) vers la moyenne des positions des agents qui leur sont proches, c'est-à-dire qui ont une distance inférieure à 1. Formellement on pourrait dire que $x_i^{(t+1)} = \frac{1}{|N_d^{(t)}(i)|} \sum_{j \in N_d^{(t)}(i)} x_j^{(t)}$ où $N_d^{(t)}(i) = \{j \text{ t.q. } |x_j^{(t)} - x_i^{(t)}| < d\}$.

\subsection{Aperçu de notre travail théorique}

Pour nous donner des suggestions le professeur nous a envoyé une présenta\-tion qu'il avait fait pour synthétiser et commenter l'article ``On Krause’s multi-agent consensus model with state-dependent connectivity'' de Vincent D. Blondel, Julien M. Hendrickx et John N. Tsitsiklis. L'argument nous intéressait et nous avons donc décidé de lire l'article entier en original pour mieux comprendre le modèle, les problématiques et les approches proposées.

Un premier aspect que nous avons étudié a été la distribution des instants auxquels deux groupes d'agents s'unifient. Pour cela nous avons écrit un simulateur spécialisé et optimisé pour exécuter un grand nombre de fois des  simulations à partir d'une situation aléatoire et obtenir des données statistiques. En représentant ces graphiques nous n'avons trouvé aucun comportement facilement descriptible et donc nous avons abandonné cette piste.

[Raphael : mets ici une description de ton premier travail sur le modèle de Krause]

Nous y avons trouvé des nouveaux problèmes ouverts, en addition de ceux que le professeur avait écrit dans la présentation. En particulier dans une section de commentaire les auteurs disaient qu'un résultat qu'il venaient de prouver (la convergence au clusters séparés d'au moins $d$) n'est pas vrai en général. Ils donnaient comme contre-exemple le cas d'agents placés sur le cercle et ils disaient que dans ce cas, même la simple convergence n’était pas prouvée. Ainsi nous avons décidé de travailler sur ce problème.

Au tout début nous avons écrit un simulateur en Python, pour nous aider à mieux comprendre les différentes situations qui peuvent se présenter. On y a estime la fréquence à laquelle ce genre de situation apparaît et comment elle évolue en fonction du rayon du cercle et de la distance d'influence. Cela nous a permis de bien voir les premiers résultats simples : la distribution équidistante (comme les racines $n$-iemes de l’unité dans le plan complexe) est la plus simple qui ne donne pas une convergence ``standard''. Cependant il y en a de plus complexes. Et dès qu'il y a un ``trou'' de largeur au moins 1 on peut se ramener au cas de la droite (en ``coupant'' le cercle) et donc on a une convergence standard.

Pour continuer a nous familiariser avec le modèle, cette fois d'un point de vue théorique, nous avons essayé de démontrer un résultat ``préliminaire'' : l'ensemble des situations initiales qui conduisent à une convergence non standard n'est pas de mesure nulle (en supposant la distribution de probabilité obtenue en tirant uniformément et indépendamment chaque agent). Cela nous a garantis que les situations que nous voulions analyser ne sont pas négligeables.

Nous sommes partis d'une des situations simples que nous avions trouvé, les agent équidistants, et nous avons ajouté du ``bruit''. Nous avons donc prouvé le théorème suivant:
\begin{theorem}
Considérons $n$ agents placés sur le cercle de rayon 1 et soit $d$ la distance d'influence. La position de l'agent $i$ est $x_i = r_i + b_i$ où $r_i = \frac{i}{n} 2 \pi$ et $b_i \in [-\epsilon, +\epsilon]$. Alors la convergence sera non standard.
\end{theorem}

Nous avons supposé que le bruit n'arrive pas à changer les relations d'influence entre les agents. On peut formaliser cela comme une contrainte sur $\epsilon$ : pour aucun $k$ on peut avoir $\frac{k}{n} 2 \pi - \epsilon < d < \frac{k}{n} 2 \pi + \epsilon$.

Après des essais numériques nous nous sommes convaincus que une situation de ce type converge vers une distribution équidistante, où l'agent $i$ est à la position $x_i + \bar b$, avec $\bar b = \frac{1}{n} \sum_{j=1}^n b_j$. Nous avons trouvé une preuve de ce résultat on utilisant les chaînes de Markov :

\begin{proof}
A toute étape chaque agent est influencé par autant d'agents à gauche que à droite. Soit $k$ ce nombre. Donc à la deuxième étape
\begin{equation*}
\begin{split}
x'_i &= x_i + \frac{1}{2k+1} \left( \sum_{j=1}^k (x_{i-j} - x_i) + \sum_{j=1}^k (x_{i+j} - x_i) \right) \\
     &= r_i + b_i + \frac{1}{2k+1} \left( \sum_{j=1}^k (r_{i-j} + b_{i-j} - r_i - b_i) + \sum_{j=1}^k (r_{i+j} + b_{i+j} - r_i - b_i) \right) \\
     &= r_i + b_i + \frac{1}{2k+1} \left( \sum_{j=1}^k (r_i - \frac{j}{n}2 \pi + b_{i-j} - r_i - b_i) + \sum_{j=1}^k (r_i + \frac{j}{n}2 \pi + b_{i+j} - r_i - b_i) \right) \\
     &= r_i + b_i + \frac{1}{2k+1} \left( \sum_{j=1}^k (b_{i-j} - b_i) + \sum_{j=1}^k (b_{i+j} - b_i) \right) \\
     &= r_i + \frac{1}{2k+1} \left( \sum_{j=1}^k b_{i-j} + b_i + \sum_{j=1}^k b_{i+j} \right) \\
\end{split}
\end{equation*}

On voit donc que le nouveau bruit de l'agent $i$ est la moyenne des bruits des agents voisins. En itérant le raisonnement on obtient qu'à tout moment le bruit d'un agent est une combinaison linéaire des bruits initiales de tous les agents. On peut donc fixer un $j$ et voir comment évoluent les coefficients de $b_j$ dans les combinaisons linéaires de tous les agents. Au début ils sont tous zéro sauf celui de l'agent $j$ lui-même. A l’étape suivante on voit que les $2k+1$ voisins de $j$ (y compris $j$) ont ce coefficient à $\frac{1}{2k+1}$. La somme donc reste 1. En fait c'est une propriété qui vaut pour toute étape, car chacun des $2k+1$ voisins d'un agent a lui aussi $2k+1$ voisins. Cela nous permet de considérer ces coefficients comme une distribution de probabilité et ensuite de voir l’évolution du système comme une chaîne de Markov. Cette chaîne est irréductible, apériodique et, en étant ses états finis, récurrente positive. Elle converge donc vers une distribution stationnaire, qui est la distribution uniforme. Le bruit initial de l'agent $j$ donc se disperse en égal mesure entre tous les agents. A la limite donc tous les agents auront le même bruit qui sera la moyenne des bruits initiaux.
\end{proof}

En suite nous avons abordé le théorème principal : il y a toujours convergence, soit standard soit non standard. Le théorème précédent en était un cas particulier mais nous ne pouvions pas utiliser les mêmes techniques sans modification parce que plusieurs hypothèses n’étaient plus valides. En particulier la somme des coefficients de la contribution de l'agent $j$ dans la position des autres agents ne reste pas 1. Et aussi la relation d'influence peut changer à chaque étape, vu que des agents peuvent s'approcher ou s’éloigner et donc entrer ou sortir l'un de l'influence de l'autre. Cela dit que la chaîne de Markov ne serait pas homogène.

Nous avons quand même essayé de nous ramener à la situation précédente en supposant que d'un certain point en avant la relation d'influence arrête de changer. Cela implique aussi que la matrice de transition ne change plus, et donc nous pouvons l'analyser. Elle est une matrice stochastique, parce que la somme des poids des arêtes qui entrent dans un agent vaut 1 (les $n$ arêtes ont toutes le même poids, qui est $\frac{1}{n}$). Les arêtes sortantes, au contraire, n'ont pas forcement somme 1. Donc, même si cette matrice est stochastique, on ne peut pas l'utiliser pour modéliser une chaîne de Markov parce que on l'utiliserait ``dans le mauvais sens'' : elle est stochastique gauche (par colonnes) mais on la multiplierait par un vecteur ligne. En tout cas, en étant stochastique, nous sachons que sa puissance $n$-ieme a une limite, et donc de cela nous déduisons que aussi les positions des agents convergent (le vecteur qui les décrit est obtenu de la multiplication de cette matrice et du vecteur des positions à l'instant auquel la relation d'influence se stabilise).

Il nous ne restait donc que à prouver que la relation se stabilise après un certain temps fini. Nous avions commencé à chercher une mesure qui décroissait, ou un argument pour prouver que dès qu'on revenait de nouveau sur une configuration déjà visitée on commençait à boucler, etc. A un certain point nous sommes tombés sur un preprint, publié sur ArXiV, d'un article qui paraissait démontrer exactement le résultat qui nous avions envisagé : ``The Hegselmann-Krause Dynamics on the Circle Converge'', écrit par Peter Hegarty, Anders Martinsson et Edvin Wedin. En le lisant nous avons en fait retrouvé notre schéma de preuve, exactement l’idée de utiliser la stabilité de la relation d'influence comme étape intermédiaire. La partie que nous manquait ils l'avaient prouvé en adaptant l’idée de ``\'energie déjà introduite d'un autre papier, pour laquelle il fallait considérer une version orientée de la relation d'influence. Les deux idées, ils ont dit, sont ``bien connues''. Nous croyons donc que une faute que nous avons commis dans le déroulement de notre projet est de ne pas avoir donné suffisamment de temps à la lecture de la littérature existante.

\subsection{Essais pratiques}

Nous avons fait un programme pour calculer puis afficher les opinions au cours du temps, ces opinion étaient un entier entre 0 et 1. Nous avons testé selon plusieurs modèles : (on note $d$ la distance d'opinion entre la personne influencée et la personne influente)
\begin{enumerate}
\item Créneau : une personne écoute les personnes d'opinion qui diffère de moins de $D \in \mathbb{R}$, toutes avec le même coeff, et pas les autres. Autrement dit la fonction qui donne le coefficient de prise en compte d'opinion en fonction de la distance d est un créneau de largeur 2D.

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatCreneau_inverse.png}
\end{center}
\caption{Créneau}
\end{figure}

\item Inverse : la fonction $\operatorname{coeff}(d)$ est $\sfrac{1}{(1+d)}$.

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatInverse_inverse.png}
\end{center}
\caption{Inverse}
\end{figure}

\item Inverse au carré : la fonction $\operatorname{coeff}(d)$ est $\sfrac{1}{(1+d^2)}$.

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatCarre_inverse.png}
\end{center}
\caption{Inverse au carré}
\end{figure}

\item Inverse au carré bis : la fonction $\operatorname{coeff}(d)$ est $\min(\sfrac{1}{d^2}, D)$ et $D$ en $d=0$.

\item Gaussien : la fonction $\operatorname{coeff}(d)$ est une gaussienne de variance $D \in \mathbb{R}$.

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatGaussien_inverse.png}
\end{center}
\caption{Gaussien}
\end{figure}

\end{enumerate}

Nous avons bien sûr fait varié $D$ et regardé les différences obtenues. Assez logiquement, plus $D$ est grand moins il y a d'opinions finales.

Certaines de ces fonctions faisaient converger très rapidement (ex : créneau vers $t \sim 5$) alors que d'autres beaucoup plus lentement (inverse au carre vers $t \sim 30000$). C'est pourquoi nous avons essayé plusieurs fonctions d'affichage :
\begin{enumerate}
\item affichage linéaire : la valeurs de l'opinion en ordonnée et le temps en abscisse, le temps ayant pour échelle 1pixel/1unité de temps jusqu'à 100pixels/1unité de temps.

\item affichage linéaire cyclique : comme l'affichage linéaire, sauf qu'une fois arrivé au bout de la fenetre on efface tout puis on affiche la suite, etc.

\item affichage logarithmique : l'abscisse est $\log(t)$, c'est à dire qu'une valeur au temps $t$ est affiché sur le pixel d'abscisse $\log(t)$.
\end{enumerate}

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatCarreLog_inverse.png}
\end{center}
\caption{Inverse au carré avec affichage logarithmique}
\end{figure}

Face à la rapidité de la convergence de certains modèles, nous avons implé\-men\-té l'inertie : plus cette inertie est importante, moins l'opinion de la personne change. C'est à dire que la personne prend en compte son opinion avec un coeff proportionnel à l'inertie. Cela permet de ralentir la convergence et d'obtenir des courbes plus jolies.
Nous avons aussi essayé une version où l'inertie change selon les personnes.

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatCreneau_inverse.png}
\end{center}
\caption{Creneau sans inertie}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatCreneauInertie_inverse.png}
\end{center}
\caption{Creneau avec inertie}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatInverse_inverse.png}
\end{center}
\caption{Inverse sans inertie}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatInverseInertie_inverse.png}
\end{center}
\caption{Inverse avec inertie}
\end{figure}

Nous avons ensuite ajouté du bruit, ie une personne a une opinion qui monte ou descend aléatoirement (en plus du changement d'opinion dû aux autres personnes) à chaque unité de temps. Nous avons mis un bruit à peu près gaussien. Ainsi nous obtenons selon les modèles une ou plusieures opinions principales qui bougent légèrement, qui sont larges avec un gros bruit et fines avec un petit bruit. Celles-ci se rejoignent parfois. De plus avec un bruit suffisament fort certaines personnes sortent des idées principales. Avec un bruit très fort on observe plus rien; et entre les deux on observe des idées principales qui bougent beaucoup, se rejoignent, se divisent, des trous d'opinions qui se créent puis disparaisent : c'est assez proche de la réalité.
Nous avons rencontré un problème dû à la fonction \texttt{rand()} en c : en utilisant beaucoup cette fonction, nous obtenous de l'aléatoire qui se répète, et du coup des opinions de personnes qui montent et descendent de la même manière.

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatCreneauBruit_inverse.png}
\end{center}
\caption{Creneau avec bruit}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatInverseBruit_inverse.png}
\end{center}
\caption{Inverse avec bruit}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatCarreBruit3_inverse.png}
\end{center}
\caption{Inverse au carré avec un peu de bruit}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatCarreBruit20_inverse.png}
\end{center}
\caption{Inverse au carré avec beaucoup de bruit}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatGaussienBruit_inverse.png}
\end{center}
\caption{Gaussien avec bruit}
\end{figure}

Nous avons ensuite essayé une version où les valeurs des opinions sont sur un cercle, cela n'a pas changé grand chose.

\begin{figure}
\begin{center}
\includegraphics[width=300]{resultatCyclique_inverse.png}
\end{center}
\caption{Creneau avec bruit et valeurs cycliques}
\end{figure}

Enfin nous avons rajouté quelques petites choses, comme le choix des couleurs pour afficher les opinions, le choix des opinions au départ (aléatoire, uniformément réparti, tous au centre, ...) ou encore l'essai d'une mesure de 'chaos' qui est la somme pour toutes les personnes de la somme des coefficient d'influence.


\end{document}          
